{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Hashes and Scores\n",
    "\n",
    "- Load in a set of hashes and distance scores that have already been calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from phaser.utils import load_labelencoders\n",
    "\n",
    "\n",
    "hash_dist_dir = r\"./demo_outputs/\"\n",
    "\n",
    "# Load the label encoders\n",
    "le = load_labelencoders(filename=\"LabelEncoders.bz2\", path=hash_dist_dir)\n",
    "\n",
    "# Get values to construct triplets\n",
    "TRANSFORMS = le[\"t\"].classes_\n",
    "METRICS = le[\"m\"].classes_\n",
    "ALGORITHMS = le[\"a\"].classes_\n",
    "\n",
    "# Load from CSV\n",
    "#df_h = pd.read_csv(os.path.join(hash_dist_dir , \"Hashes.csv.bz2\"))\n",
    "#df_d = pd.read_csv(os.path.join(hash_dist_dir , \"Distances.csv.bz2\"))\n",
    "\n",
    "# Load from the df files instead (a better option for larger datasets)\n",
    "df_h = load(os.path.join(hash_dist_dir , \"Hashes.df.bz2\"))\n",
    "df_d = load(os.path.join(hash_dist_dir , \"Distances.df.bz2\"))\n",
    "\n",
    "# Inter (0), Intra (1)\n",
    "intra_df = df_d[df_d[\"class\"] == 1]\n",
    "inter_df = df_d[df_d[\"class\"] == 0]\n",
    "\n",
    "print(df_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Plots\n",
    "\n",
    "- Run this before the plot segments below.\n",
    "- Allows for some configurability of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phaser.evaluation import MetricMaker\n",
    "from phaser.plotting import  hist_fig, kde_ax, eer_ax, roc_ax\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore Seaborn warnings due to underlying package using future deprecated calls\n",
    "\n",
    "\n",
    "#define widgets\n",
    "tselect = widgets.Dropdown(\n",
    "        options=TRANSFORMS[:-1],\n",
    "        description='Transform'\n",
    "    )\n",
    "mselect = widgets.Dropdown(\n",
    "        options=METRICS,\n",
    "        description='Metric'\n",
    "    )\n",
    "aselect = widgets.Dropdown(\n",
    "        options=ALGORITHMS,\n",
    "        description='Algorithm'\n",
    "    )\n",
    "modeselect = widgets.Dropdown(\n",
    "        options=[\"inter\", \"intra\"],\n",
    "        description='Comparison Mode'\n",
    "    )\n",
    "\n",
    "\n",
    "### Hist plots, separate for intra/inter\n",
    "def plot_image(transform, mode, bins=25,  width=8, height=6):\n",
    "    data = df_h\n",
    "    if transform != 'Select' and bins > 1:\n",
    "        if mode == \"inter\":\n",
    "            fig = hist_fig(inter_df, label_encoding=le, transform=transform, interactive=True, bins=bins, figsize=(width,height))\n",
    "        elif mode == \"intra\":\n",
    "            fig = hist_fig(intra_df, label_encoding=le, transform=transform, interactive=True, bins=bins, figsize=(width,height))\n",
    "        fig.suptitle(\"Similarity Histograms\")\n",
    "        \n",
    "\n",
    "### KDE multi plot\n",
    "def kde_plot_multi(transform, width=8, height=6):\n",
    "    if transform != 'Select':\n",
    "\n",
    "        #t_label = le_a.transform(np.array(transform).ravel()\n",
    "        n_cols = len(METRICS)\n",
    "        n_rows = len(ALGORITHMS)\n",
    "\n",
    "        # Subset data\n",
    "        fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(width,height), constrained_layout=True, \n",
    "                                 sharex=True, sharey=False, squeeze=False)\n",
    "                                 \n",
    "        for col_i, metric in enumerate(METRICS):\n",
    "            for row_i, algo in enumerate(ALGORITHMS):\n",
    "                    # Transform strings to labels\n",
    "                    m_label = le[\"m\"].transform(np.array(metric).ravel())\n",
    "                    a_label = le[\"a\"].transform(np.array(algo).ravel())\n",
    "\n",
    "                    # Subset data and get the distances for the chosen transformation\n",
    "                    _X = df_d.query(f\"algo=={a_label} and metric == {m_label}\")\n",
    "                    \n",
    "\n",
    "                    kde_ax(_X, transform, label_encoding=le, fill=True, title=f\"{algo}-{metric}\", ax=axes[row_i, col_i])\n",
    "        fig.suptitle(\"Inter/Intra-Score KDE Plots\")\n",
    "        \n",
    "\n",
    "### EER multi plot\n",
    "def eer_plot_multi(transform, width=8, height=6):\n",
    "    if transform != 'Select':\n",
    "\n",
    "        n_cols = len(METRICS)\n",
    "        n_rows = len(ALGORITHMS)\n",
    "        # Subset data\n",
    "        fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(width, height), constrained_layout=True, \n",
    "                                 sharex=True, sharey=False, squeeze=False)\n",
    "                                 \n",
    "        for col_i, metric in enumerate(METRICS):\n",
    "            for row_i, algo in enumerate(ALGORITHMS):\n",
    "                    # Transform strings to labels\n",
    "                    m_label = le[\"m\"].transform(np.array(metric).ravel())\n",
    "                    a_label = le[\"a\"].transform(np.array(algo).ravel())\n",
    "\n",
    "                    # Subset data and get the distances for the chosen transformation\n",
    "                    _X = df_d.query(f\"algo=={a_label} and metric == {m_label}\")\n",
    "\n",
    "                    # get similarities and true class labels\n",
    "                    y_true = _X[\"class\"]\n",
    "                    y_similarity = _X[transform]\n",
    "\n",
    "                    # Prepare metrics for plotting EER and AUC\n",
    "                    mm = MetricMaker(y_true=y_true, y_similarity=y_similarity, weighted=False)\n",
    "                    \n",
    "                    # Set threshold\n",
    "                    threshold = mm.eer_thresh\n",
    "\n",
    "                    # Make predictions and compute cm using EER\n",
    "                    eer_ax(mm.fpr, mm.tpr, mm.thresholds, threshold=threshold, legend=f\"\", title=f\"{algo}-{metric}\", ax=axes[row_i, col_i])\n",
    "        fig.suptitle(\"EER Plots\")\n",
    "        \n",
    "\n",
    "### ROC multi plot\n",
    "def roc_plot_multi(transform, width=8, height=6):\n",
    "    if transform != 'Select':\n",
    "\n",
    "        n_cols = len(METRICS)\n",
    "        n_rows = len(ALGORITHMS)\n",
    "        # Subset data\n",
    "        fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(width,height), constrained_layout=True, \n",
    "                                 sharex=True, sharey=False, squeeze=False)\n",
    "                                 \n",
    "        for col_i, metric in enumerate(METRICS):\n",
    "            for row_i, algo in enumerate(ALGORITHMS):\n",
    "                    # Transform strings to labels\n",
    "                    m_label = le[\"m\"].transform(np.array(metric).ravel())\n",
    "                    a_label = le[\"a\"].transform(np.array(algo).ravel())\n",
    "\n",
    "                    # Subset data and get the distances for the chosen transformation\n",
    "                    _X = df_d.query(f\"algo=={a_label} and metric == {m_label}\")\n",
    "\n",
    "                    # get similarities and true class labels\n",
    "                    y_true = _X[\"class\"]\n",
    "                    y_similarity = _X[transform]\n",
    "\n",
    "                    # Prepare metrics for plotting EER and AUC\n",
    "                    mm = MetricMaker(y_true=y_true, y_similarity=y_similarity, weighted=False)\n",
    "                    \n",
    "\n",
    "\n",
    "                    # Make predictions and compute cm using EER\n",
    "                    roc_ax(mm.fpr, mm.tpr, mm.auc, title=f\"{algo}-{metric}\", ax=axes[row_i, col_i])\n",
    "        fig.suptitle(\"ROC Plots\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Score Histograms\n",
    "\n",
    "- Normalised counts of scores for each hash/transform\n",
    "- Same data as the KDE plots, but allows for a better understanding of any gaps in the distributions.\n",
    "- Updates as long as the number of bins is over 1.\n",
    "- Ideally: Inter distribution is normally distributed around 0.5, while the intra similarity is as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity Score Histograms\n",
    "h = interactive(plot_image, transform=tselect, mode=modeselect)  # optional: save_location\n",
    "display(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Density Estimation (KDE)\n",
    "\n",
    "- Combined plot for Inter/Intra scores.\n",
    "- More or less the same as Histograms, but estimates probability density.\n",
    "- Ideally, both classes should be completely non-overlapping. Overlap is expected for difficult transforms and indicates difficulty in setting a threshold to separate them, resulting in Fasle Positives / False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity Kernel Density Estimation (KDE) for inter/intra classes\n",
    "k = interactive(kde_plot_multi, transform=tselect)\n",
    "display(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Rate\n",
    "\n",
    "- Visualise the False Positive Rate (FPR) and False Negative Rate (FNR) trade-offs across the similarity score spectrum.\n",
    "- The vertical line represents the score at which the where FPR == FNR, i.e. Thje Equal Error Rate Threshold (EERt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal Error Rate (EER) similarity plots\n",
    "eer = interactive(eer_plot_multi, transform=tselect)\n",
    "display(eer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receiver Operating Characteristic (ROC)\n",
    "\n",
    "- Plot TPR vs FPR to visualise trade-offs.\n",
    "- Provides Area Under the Curve (AUC) as a means of summarising overall performance. Larger AUC (up to 1.0) is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receiver Operator Characteristic (ROC) similarity plots\n",
    "roc = interactive(roc_plot_multi, transform=tselect)\n",
    "display(roc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perceptual-framework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
